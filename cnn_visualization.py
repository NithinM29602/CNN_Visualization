# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FohxFnRcBTYUMzAu4AZRqdXS9Hvaeqdj
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import torchvision
import torch.nn as nn
import torchvision.models as models
from PIL import Image
import os
import numpy as np
from mpl_toolkits.axes_grid1 import ImageGrid
import matplotlib.pyplot as plt
# %matplotlib inline

device = ('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize((255,255)),
    torchvision.transforms.CenterCrop((224,224)),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

model = models.vgg16(pretrained = True)

with open("/content/sample_data/imagenet_class_index.txt","r") as f:
  lines = f.readlines()

class_idx_dict = {}
for line in lines:
  line = line.strip()
  key , value = line.split(':')
  key = key.strip()
  value = value.strip()
  class_idx_dict[key] = value


class_idx = [class_idx_dict[f"{i}"] for i in class_idx_dict.keys()]

for params in model.parameters():
  params.requires_grad == False

model.to(device)

model.eval()

# for name, layer in model.named_modules():
#   if isinstance(layer, torch.nn.Conv2d):
#     weights = layer.weight.shape
#     bias = layer.bias.shape
#     name = name.replace('features.','')
#     print(f"Conv Layer {name}")
#     print(f"Weights Shape : {weights}")
#     print(f"Bias Shape : ", bias if bias is not None else None )
#     print('-'*40)

name_list = {}
i=1
for name, layer in model.features.named_children():
  if isinstance(layer, torch.nn.Conv2d):
    name_list[i] = int(name)
    i += 1

print(name_list)

user_input = int(input("Enter the Conv Layer which you need to see : "))
conv_layer_num = name_list[user_input]
conv_layer_name = "Conv_Layer" + str(conv_layer_num)

#filters

# for name, layer in model.features.named_children():
#   if int(name) == conv_layer_num:
#     filter, bias = layer.weight, layer.bias
#
# f_max, f_min = filter.max(), filter.min()
# filter = (filter - f_min) / (f_max - f_min)
#
# # torch.Size([64, 3, 3, 3]) it is like (out_channels, input_channels, height, width)
# # Filters
# plt.figure(figsize=(5,5))
# num_filter = filter.data.size(0)
# print(num_filter)
# print(filter.data[1].shape)
# # print(filter.data.size)
#
# for i in range(6):
#   filter_data = filter.data[i].cpu().numpy().transpose(1,2,0)
#   # print(filter_data.shape)
#   num_channels = len(filter_data[0])
#   for j in range(num_channels):
#       plt.subplot(1, num_channels, j + 1)
#       plt.imshow(filter_data[:,:,j], cmap='gray')  # Visualize each channel
#       plt.axis('off')
#
#
# #
# print(filter.shape)
# filter_data = filter.data.cpu().numpy().transpose(0,2,3,1)
# print(filter.shape)
# for j in range(1):
#    plt.subplot(1, num_channels, j + 1)
#    plt.imshow(filter_data[1,:,:,0], cmap='gray')  # Visualize each channel
#    plt.axis('off')

# Feature Maps

conv_layers = {}

def get_conv_layers(name):
    def hook(module, input, output):
        conv_layers[name] = output.detach()
    return hook

# Register a forward hook to capture the output of the desired layer (conv1)
model.features[conv_layer_num].register_forward_hook(get_conv_layers(conv_layer_name))

image = Image.open('Images/cricketer.jpeg')
transformed_image = transform(image)
final_image = transformed_image.unsqueeze(0)
final_image = final_image.to(device)
output = model(final_image)

final_output = conv_layers[conv_layer_name].squeeze(0)

final_data = final_output.cpu().numpy()
final_data = final_data.transpose(1,2,0)
s = final_data.shape

fig = plt.figure(figsize=(30,20))
total_filters = s[2]
no_rows = (total_filters // 6) + 1
# total_grids =  no_rows * 6
# non_required_grids = total_grids - total_filters

grid = ImageGrid(fig, 111,
                 nrows_ncols=(no_rows, 6),
                 axes_pad=0.3,
                 )
for i in range(total_filters):
  grid[i].imshow(final_data[:,:,i-1], cmap='gray')
  grid[i].axis('off')


# for _ in range(non_required_grids):
#   grid[-1].remove()


plt.show()